{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2 Exercises for COMP 433 (Deep Learning)"
      ],
      "metadata": {
        "id": "gZ8rj_itne_8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDfbqtKuveLv"
      },
      "source": [
        "## Exercise 1: Data Visualization and Multi-Class Classification\n",
        "\n",
        "\n",
        "In this exercise, we will work with a dataset called [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) which has 3 categories and 178 samples. For each sample there are 13 features.\n",
        "\n",
        "Start by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV4VKRTEvjMD"
      },
      "source": [
        "#Load sklearn data\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "#targets for each sample\n",
        "print(data.target.shape)\n",
        "# data\n",
        "print(data.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class distribution refers to the number of examples that belong to each class.\n",
        "\n",
        "We'll plot the class distribution at various points in the lab. Complete the following function. We'll be using this function at various points in the lab."
      ],
      "metadata": {
        "id": "KrQY3ZLdnB-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_class_distribution(targets):\n",
        "  plt.figure()\n",
        "  width = 0.2\n",
        "  for i in range(0, 3):\n",
        "    # use logical ðŸ¤“ indexing on targets\n",
        "    plt.bar(i, np.shape(\"CHANGE ME CHANGE ME\"), width)\n",
        "  plt.xticks([0, 1, 2])\n",
        "  plt.show()\n",
        "\n",
        "plot_class_distribution(data.target)"
      ],
      "metadata": {
        "id": "4z8sEJO7aPCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rcXIvDsF7QV"
      },
      "source": [
        "\n",
        "\n",
        " Pick any **two** models from the list of sklearn models below:\n",
        "\n",
        " *   [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "*   [Ridge Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n",
        "\n",
        "*   [Random Forset Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "\n",
        "Do not worry if we have not covered this algorithm in class, the goal is to get familiar with applying ML algorithms in sklearn.\n",
        "\n",
        "----\n",
        "Requirements:\n",
        "\n",
        "1. First start by **splitting** your data into two sets: train and test using the 80/20 split rule. Utilize [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "2. **Train** your 2 models of choice using the train set. Make sure to set the appropriate hyperparameters for each model.\n",
        "3. **Evaluate** your trained models on both the train and test data by getting the accuracy on both the training and test sets. Utilize [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
        "\n",
        "Note: For reproducibility fix the random_state=42.\n",
        "Your test accuracy should be >90%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMykNVd-F-zN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Split into train and test set\n",
        "\n",
        "#Visualize the class distribution of train and test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDhtebNWsXaQ"
      },
      "source": [
        "#Train and evaluate accuracy with 2 different models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the class distributions of the fitted models."
      ],
      "metadata": {
        "id": "pI3ioBtixUm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the class distributions of the trained models on some data\n"
      ],
      "metadata": {
        "id": "zmFEiVVzxXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does it look like your trained models match the class distributions of your training data? What about test data?\n",
        "\n",
        "Explain."
      ],
      "metadata": {
        "id": "K44HC4ACxXt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your answers in this cell here (double click on it first)."
      ],
      "metadata": {
        "id": "eLvBXQTcxoMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2:\n",
        "# **Hyperparameter tuning**\n",
        "\n",
        "Hyperparameter tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. Hyperparameters refer to a set of parameters whose values are chosen by the machine learning practitioner and unchanged by the learning algorithm, while parameters refer to a set of values changed by the learning algorithm.\n",
        "\n",
        "\n",
        "Hyperparameter tuning methods, such as GridSearch, iterate over a set of values for each hyperparameter and evaluates models trained with these values on a validation set. Loss is often the metric looked at for models with the best fit, but accuracy can also be used.\n",
        "\n",
        "Once the best set of values for hyperparameters has been found for a particular model, the model is trained on the full training set and then evaluated on the test set.\n",
        "\n",
        "\n",
        "In this exercise, you will implement a grid search over the hyperparameter `C` of a LogisticRegression model.\n",
        "\n",
        "1. Define `C_values = [0.1, 0.4, 1.0, 10]` and split the training set from the previous exercise into a train and validation set using `train_test_split`, you can take 20% of the train set for validation.\n",
        "2. Utilize a for loop to iterate over the values of `C_values`, and define a LogisticRegression model with `C=C_values[index]`.\n",
        "3. Train the model and evaluate the cross entropy loss or accuracy on the validation set.\n",
        "4. Choose the best performing model and perform training on the full train set, with evaluation on the test set."
      ],
      "metadata": {
        "id": "iiwxejkrhJBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hyp_tuning():\n",
        "    #SPLIT DATASET\n",
        "\n",
        "    #INSTANTIATE SKLEARN MODEL WITH C_VALUE\n",
        "\n",
        "    #CALL .FIT FUNCTION\n",
        "\n",
        "    #EVALUATE WITH VALIDATION DATASET"
      ],
      "metadata": {
        "id": "8sEGt6eblHSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "FcmVLWy33Bjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: KNN implementation\n",
        "\n",
        "\n",
        "In this exercise, we will implement the K Nearest Neighbor algorithm on the MNIST and the CIFAR-10 datasets"
      ],
      "metadata": {
        "id": "ER19OWD6JhB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data understanding and visualization"
      ],
      "metadata": {
        "id": "Hn6E6KoTLmFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "#Inspect and understand the following functions\n",
        "def _extract_tensors(dataset, num=None):\n",
        "  \"\"\"\n",
        "  Extract the data and labels from a CIFAR10 dataset object and convert them to tensors.\n",
        "\n",
        "  Input:\n",
        "  - dset: A torchvision.datasets.CIFAR10 object\n",
        "  - num: Optional. If provided, the number of samples to keep.\n",
        "\n",
        "  Returns:\n",
        "  - x: float32 tensor of shape (N, 3, 32, 32)\n",
        "  - y: int64 tensor of shape (N,)\n",
        "  \"\"\"\n",
        "  x = torch.tensor(dataset.data, dtype=torch.float32).permute(0, 3, 1, 2).div_(255)\n",
        "  y = torch.tensor(dataset.targets, dtype=torch.int64)\n",
        "  if num is not None:\n",
        "    if num <= 0 or num > x.shape[0]:\n",
        "      raise ValueError('Invalid value num=%d; must be in the range [0, %d]'\n",
        "                       % (num, x.shape[0]))\n",
        "    x = x[:num].clone()\n",
        "    y = y[:num].clone()\n",
        "  return x, y\n",
        "\n",
        "\n",
        "def cifar10(num_train=None, num_test=None):\n",
        "  \"\"\"\n",
        "  Return the CIFAR10 dataset, automatically downloading it if necessary. This function can also subsample the dataset.\n",
        "\n",
        "  Inputs:\n",
        "  - num_train: [Optional] How many samples to keep from the training set.\n",
        "    If not provided, then keep the entire training set.\n",
        "  - num_test: [Optional] How many samples to keep from the test set.\n",
        "    If not provided, then keep the entire test set.\n",
        "\n",
        "  Returns:\n",
        "  - x_train: float32 tensor of shape (num_train, 3, 32, 32)\n",
        "  - y_train: int64 tensor of shape (num_train, 3, 32, 32)\n",
        "  - x_test: float32 tensor of shape (num_test, 3, 32, 32)\n",
        "  - y_test: int64 tensor of shape (num_test, 3, 32, 32)\n",
        "  \"\"\"\n",
        "  download = not os.path.isdir('cifar-10-batches-py')\n",
        "  dset_train = CIFAR10(root='.', download=download, train=True)\n",
        "  dset_test = CIFAR10(root='.', train=False)\n",
        "  x_train, y_train = _extract_tensors(dset_train, num_train)\n",
        "  x_test, y_test = _extract_tensors(dset_test, num_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "l-ARY7NlIsQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 1000\n",
        "p = .4\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = cifar10(N, int(p*N))\n",
        "\n",
        "# Write the code to show the shape of training and testing data\n",
        "\n",
        "\n",
        "# Write the code to show a random image of training set\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcFtaN76M5nd",
        "outputId": "e16aff05-3dc1-4fe1-8762-16774fc065a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:04<00:00, 36021423.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing distance functions"
      ],
      "metadata": {
        "id": "lC30jaANO4Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_distances_one_loop(x_train, x_test):\n",
        "  \"\"\"\n",
        "  Computes the squared Euclidean distance between each element of the training set and each element of the test set. Images should be flattened and treated as vectors.\n",
        "  Your implementation should only use a single loop over the training data. Inputs should not be modified.\n",
        "\n",
        "  NOTE: Your implementation may not use `torch.norm`, `torch.dist`, `torch.cdist`, or their instance method variants x.norm / x.dist / x.cdist. You may not use any functions from torch.nn or torch.nn.functional.\n",
        "\n",
        "  Inputs:\n",
        "  - x_train: Torch tensor of shape (num_train, D1, D2, ...)\n",
        "  - x_test: Torch tensor of shape (num_test, D1, D2, ...)\n",
        "\n",
        "  Returns:\n",
        "  - dists: Torch tensor of shape (num_train, num_test) where dists[i, j] is the squared Euclidean distance between the ith training point and the jth test point.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize dists to be a tensor of shape (num_train, num_test) with the\n",
        "  # same datatype and device as x_train\n",
        "  num_train = x_train.shape[0]\n",
        "  num_test = x_test.shape[0]\n",
        "  dists = x_train.new_zeros(num_train, num_test)\n",
        "  ##############################################################################\n",
        "  # TODO: Implement this function using only a single loop over x_train.       #\n",
        "  #                                                                            #\n",
        "  # You may not use torch.norm (or its instance method variant), nor any       #\n",
        "  # functions from torch.nn or torch.nn.functional.                            #\n",
        "  ##############################################################################\n",
        "  # Replace \"pass\" statement with your code\n",
        "  pass\n",
        "  ##############################################################################\n",
        "  #                             END OF YOUR CODE                               #\n",
        "  ##############################################################################\n",
        "  return dists\n",
        "\n",
        "\n",
        "def compute_distances_no_loops(x_train, x_test):\n",
        "  \"\"\"\n",
        "  Computes the squared Euclidean distance between each element of the training set and each element of the test set. Images should be flattened and treated as vectors.\n",
        "\n",
        "  This implementation should not use any Python loops. For memory-efficiency, it also should not create any large intermediate tensors; in particular you should not create any intermediate tensors with O(num_train*num_test) elements.\n",
        "  Similar to compute_distances_two_loops, this should be able to handle inputs with any number of dimensions. The inputs should not be modified.\n",
        "\n",
        "  NOTE: Your implementation may not use `torch.norm`, `torch.dist`, `torch.cdist`, or their instance method variants x.norm / x.dist / x.cdist. You may not use any functions from torch.nn or torch.nn.functional.\n",
        "\n",
        "  Inputs:\n",
        "  - x_train: Torch tensor of shape (num_train, C, H, W)\n",
        "  - x_test: Torch tensor of shape (num_test, C, H, W)\n",
        "\n",
        "  Returns:\n",
        "  - dists: Torch tensor of shape (num_train, num_test) where dists[i, j] is the squared Euclidean distance between the ith training point and the jth test point.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize dists to be a tensor of shape (num_train, num_test) with the  same datatype and device as x_train\n",
        "  num_train = x_train.shape[0]\n",
        "  num_test = x_test.shape[0]\n",
        "  dists = x_train.new_zeros(num_train, num_test)\n",
        "  ##############################################################################\n",
        "  # TODO: Implement this function without using any explicit loops and without #\n",
        "  # creating any intermediate tensors with O(num_train * num_test) elements.   #\n",
        "  #                                                                            #\n",
        "  # You may not use torch.norm (or its instance method variant), nor any       #\n",
        "  # functions from torch.nn or torch.nn.functional.                            #\n",
        "  #                                                                            #\n",
        "  # HINT: Try to formulate the Euclidean distance using two broadcast sums     #\n",
        "  #       and a matrix multiply.                                               #\n",
        "  ##############################################################################\n",
        "  # Replace \"pass\" statement with your code\n",
        "  pass\n",
        "  ##############################################################################\n",
        "  #                             END OF YOUR CODE                               #\n",
        "  ##############################################################################\n",
        "  return dists\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "afnLxoiWPPXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the distance functions"
      ],
      "metadata": {
        "id": "LGrxLYRsRr9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the code to test the previous functions, compare their results (absolute difference) and their computational time, use the two following random data. Use the \"time\" librairy to compute the computational time\n",
        "\n",
        "x_train_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
        "x_test_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
        "\n",
        "#Your code here"
      ],
      "metadata": {
        "id": "9X44GzG-R241"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing the KNN classifier"
      ],
      "metadata": {
        "id": "t1_JjTEhTE5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnnClassifier:\n",
        "  def __init__(self, x_train, y_train):\n",
        "    \"\"\"\n",
        "    Create a new K-Nearest Neighbor classifier with the specified training data.\n",
        "    In the initializer we simply memorize the provided training data.\n",
        "\n",
        "    Inputs:\n",
        "    - x_train: Torch tensor of shape (num_train, C, H, W) giving training data\n",
        "    - y_train: int64 torch tensor of shape (num_train,) giving training labels\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the initializer for this class. It should perform no    #\n",
        "    # computation and simply memorize the training data.                      #\n",
        "    ###########################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "\n",
        "  def predict(self, x_test, k=1):\n",
        "    \"\"\"\n",
        "    Make predictions using the classifier.\n",
        "\n",
        "    Inputs:\n",
        "    - x_test: Torch tensor of shape (num_test, C, H, W) giving test samples\n",
        "    - k: The number of neighbors to use for predictions\n",
        "\n",
        "    Returns:\n",
        "    - y_test_pred: Torch tensor of shape (num_test,) giving predicted labels\n",
        "      for the test samples.\n",
        "    \"\"\"\n",
        "    y_test_pred = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement this method. You should use the functions you wrote     #\n",
        "    # above for computing distances (use the no-loop variant) and to predict  #\n",
        "    # output labels.\n",
        "    ###########################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "    return y_test_pred\n",
        "\n",
        "  def check_accuracy(self, x_test, y_test, k=1, quiet=False):\n",
        "    \"\"\"\n",
        "    Utility method for checking the accuracy of this classifier on test data.\n",
        "    Returns the accuracy of the classifier on the test data, and also prints a\n",
        "    message giving the accuracy.\n",
        "\n",
        "    Inputs:\n",
        "    - x_test: Torch tensor of shape (num_test, C, H, W) giving test samples\n",
        "    - y_test: int64 torch tensor of shape (num_test,) giving test labels\n",
        "    - k: The number of neighbors to use for prediction\n",
        "    - quiet: If True, don't print a message.\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: Accuracy of this classifier on the test data, as a percent.\n",
        "      Python float in the range [0, 100]\n",
        "    \"\"\"\n",
        "    y_test_pred = self.predict(x_test, k=k)\n",
        "    num_samples = x_test.shape[0]\n",
        "    num_correct = (y_test == y_test_pred).sum().item()\n",
        "    accuracy = 100.0 * num_correct / num_samples\n",
        "    msg = (f'Got {num_correct} / {num_samples} correct; '\n",
        "           f'accuracy is {accuracy:.2f}%')\n",
        "    if not quiet:\n",
        "      print(msg)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "FwcG3CTPTMUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the KNN Classifier"
      ],
      "metadata": {
        "id": "GyMFMz0OY68f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read again the training and testing data\n",
        "\n",
        "N = 5000\n",
        "p = .2\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = cifar10(N, int(p*N))\n",
        "\n",
        "\n",
        "classifier = KnnClassifier(X_train, y_train)\n",
        "\n",
        "#check the accuracy\n",
        "classifier.check_accuracy(X_test, y_test, k=1)"
      ],
      "metadata": {
        "id": "L3bJuMb4Y2lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hold-out validation"
      ],
      "metadata": {
        "id": "giuSOafJZwVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(111)\n",
        "# Split the training data into training and validation set (75-25), 75% for training and 25% for validation, randomly sample train and validation indexes without repetition\n",
        "\n",
        "# Create several KNN classifier by variying K (up to 10), evaluate their accuracy on the validation set\n",
        "\n",
        "# Plot the curve accuracy vs value of K\n",
        "\n",
        "# Print the best value of K\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m7yuKJAGZ93I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Final model\n",
        "\n",
        "#Compute the accuracy on testing data for the optimal K obtained after hold-out validation"
      ],
      "metadata": {
        "id": "MW4a-sGAbZSm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}